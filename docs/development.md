## ELI5

Steam breaks your game files into ~1MB “lego blocks.” If your build process shuffles big packed files, lots of blocks change, so players download far more than they should. Your tool measures that “wasted” download *before* you ship and fails the build if it’s too big. ([partner.steamgames.com][1])

## FT/Guardian-style summary

This is a credible micro-SaaS/CI quality gate: convert SteamPipe’s patching mechanics (chunking + manifests) into a measurable engineering KPI (“delta efficiency”), then operationalize it via baselines, thresholds, and PR annotations. Steam already lets partners *see* update size before setting a build live, but that’s still downstream; your wedge is moving detection upstream into CI and tying causes → fixes (pack-file churn, TOC layout, cross-asset compression). ([partner.steamgames.com][2])

---

## Top 3 things to know

1. **Feasibility is high if you stay inside SteamPipe outputs.** SteamPipe builds write logs and **depot manifests** into `BuildOutput`; “Preview” builds can emit logs/manifests without uploading—ideal for CI. ([partner.steamgames.com][2])
2. **The core economics are real and common.** SteamPipe chunks files into ~1MB blocks; pack-file ordering/TOC patterns can cause “catastrophic” patch bloat where small edits force lots of new chunks. ([partner.steamgames.com][1])
3. **The main platform risk is *how* you source data.** A read-only analyzer that consumes customer-owned SteamPipe outputs is low drama; anything that looks like DepotDownloader/SteamKit-based CDN pulling (piracy-adjacent) is where you invite attention and breakage. ([GitHub][3])

---

## Next 5 (the 80/20)

1. **Uniqueness:** I did not find an obvious dedicated “SteamPipe patch waste CI gate” product in quick scanning; the official guidance still points devs to manual binary diffs (e.g., Beyond Compare) when patch sizes look wrong. That suggests whitespace. ([partner.steamgames.com][1])
2. **Steam already has a partial substitute:** SteamPipe/Steamworks highlights the *ability to see update size before setting live*—but that’s after you’ve built and typically uploaded. Your product wins by preventing bad builds earlier and explaining root causes. ([partner.steamgames.com][2])
3. **Pain is visible in the wild:** Unreal teams regularly complain that tiny changes produce huge Steam updates because `.pak` churn dominates. ([Epic Developer Community Forums][4])
4. **Moat is not the math; it’s the heuristics + workflow lock-in.** Chunk-diff math is reproducible; hard-to-copy value is: engine-aware diagnosis (“this looks like TOC offsets scattered”), baselines per branch, and PR/Slack/GitHub annotations that become policy. ([partner.steamgames.com][1])
5. **The wedge feature that sells:** “This PR increases predicted patch download by +42% vs `main` baseline; top offenders: `Game.pak` reorder, TOC diffusion; suggested fix: Unreal padding align 1MB / split packs by realm.” Unreal-specific mitigations are explicitly called out by Valve. ([partner.steamgames.com][1])

---

## Is it unique?

**Moderately unique (good enough).**
*What exists:* official best-practice docs + Steamworks UI showing update size downstream + ad-hoc manual diffing. ([partner.steamgames.com][2])
*What I didn’t see:* a mainstream, CI-first analyzer that ingests SteamPipe build outputs and produces a “patch bloat budget” gate.

**Risk:** a competitor can be built; your differentiation must be **opinionated defaults** + **engine signatures** + **team workflow hooks**.

---

## Would Steam shut it down?

### Low risk if you do this

* Consume **local SteamPipe outputs** (logs/manifests/chunk caches) generated by the partner’s own build pipeline. ([partner.steamgames.com][2])
* Don’t ship Valve binaries; require the customer to install Steamworks SDK/SteamCMD themselves.
* Be explicit: “not affiliated with Valve,” avoid trademarks in product name/domain.

### Higher risk if you do this

* Pull manifests/depots from Steam infrastructure using reverse-engineered client/network libraries or scraping (fragile + policy + optics). The existence/maintenance of tools in that space is real, but it’s the wrong association for a B2B devtool. ([GitHub][3])

(You still need to read your Steamworks agreements; this is practical risk framing, not legal advice.)

---

## Could others implement it easily?

**Yes—if you only ship “delta %” math.**
**No—if you ship “delta % + why + what to change + CI policy + baselines + engine pack signatures.”** The latter is where time accrues and where you can win.

---

## How long to execute and ship?

### MVP (CLI + CI gate) — **~1–2 weeks**

* Run SteamPipe **Preview** build in CI to emit manifests/logs. ([partner.steamgames.com][2])
* Parse “old vs new” manifests; compute changed chunk volume; output JSON/Markdown; fail if threshold exceeded.

### V1 (dashboard + baselines + diagnostics) — **~3–6 weeks**

* Store per-branch baselines; trend charts; top-offender files; rule-based diagnoses (reorder, TOC diffusion, giant pack touched, cross-asset compression).
* PR comments + GitHub/GitLab integrations.

### V2 (moat) — **~6–12+ weeks**

* Engine-specific detectors (Unreal/Unity/custom), auto-remediation playbooks, and “budget policies” by depot/branch/team.

---

## Product shape that minimizes risk and maximizes pull

* **Packaging:** “local-first” binary + optional hosted dashboard (upload only summary metrics, not raw manifests/logs).
* **Hooks:** GitHub Action + GitLab CI template + Jenkins step.
* **Pricing:** aligns with value: per-app or per-depot tier; charge more for multi-branch baselines and PR automation.

---

## One-line summaries + vocab

* **Deutsch:** Ein CI-Tool, das SteamPipe-Patch-Verschwendung früh erkennt und Builds bei übergroßen Deltas blockiert.
* **Español (vocab):** desperdicio = waste; parche = patch; eficiencia = efficiency; manifiesto = manifest; umbral = threshold.
* **Italiano (vocab):** spreco = waste; patch = aggiornamento; efficienza = efficiency; manifesto = manifest; soglia = threshold.

---

## Imaginary advisory board (contrasting advice)

### Builders / empiricists

* **Feynman / Von Neumann / Tesla / Da Vinci:** Don’t debate abstractions—instrument the pipeline, define a metric, make it falsifiable, and automate enforcement. If you can’t measure “waste,” you don’t own it.
* **Wittgenstein / Aristotle:** Define terms precisely: “predicted download” vs “on-disk churn” vs “client patch time.” Ambiguity kills trust.

### Market / power skeptics

* **Marx / Debord / Adorno / Foucault / Butler:** Your customer is not “gamedev,” it’s *release governance under platform constraints*. Sell legitimacy: policy, auditability, and reduced firefighting—because orgs buy control.
* **Chomsky / John N. Gray:** Assume incentives drift: if Valve changes internals, your product must degrade gracefully (heuristics + best-effort), not pretend omniscience.

### Existential / moral realists

* **Camus / Schopenhauer / Freud / Lacan / Confucius / Lao Tzu / Zhuangzi / Kant / Hegel / Voltaire / Montaigne / Derrida / Spinoza / Heidegger:** The danger is obsessive optimization theatre. Make the tool enforce a *small number of sane budgets* and prevent pointless suffering (late-night “why is the patch 20GB?”).

### Poets / communicators

* **Shakespeare / Dickens / Frida Kahlo:** The report must tell a human story: “one file caused 80% of the pain; here’s what to do next.” Otherwise it’s another dashboard nobody reads.

**Synthesis (actionable):** Ship a CI-first “patch bloat budget” gate using SteamPipe Preview outputs, then differentiate with engine-aware diagnosis and workflow enforcement—not prettier charts.

---

## Spaced repetition (quick self-test)

1. What SteamPipe chunk size is referenced in official docs, and why does reordering hurt? ([partner.steamgames.com][1])
2. Which SteamPipe build mode is ideal for CI because it can output logs/manifests without uploading? ([partner.steamgames.com][2])
3. Name two pack-file behaviors Valve warns can cause outsized patch sizes. ([partner.steamgames.com][1])
4. What implementation choice most increases “Steam might intervene” risk? ([GitHub][3])

[1]: https://partner.steamgames.com/doc/sdk/uploading "Uploading to Steam (Steamworks Documentation)"
[2]: https://partner.steamgames.com/doc/sdk/uploading?utm_source=chatgpt.com "Uploading to Steam (Steamworks Documentation)"
[3]: https://github.com/SteamRE/DepotDownloader?utm_source=chatgpt.com "SteamRE/DepotDownloader: Steam depot downloader ..."
[4]: https://forums.unrealengine.com/t/steam-update-size/480513?utm_source=chatgpt.com "Steam Update Size - Platform & Builds"


## ELI5

Your tool is a “smoke alarm” for Steam updates: it inspects SteamPipe build outputs and warns when a small change will force players to download a huge patch (often because pack files get reshuffled or their tables-of-contents churn). SteamPipe explicitly documents these failure modes and even recommends contacting Valve when they occur—so the problem is real; the risk is mainly legal/branding/data-handling and overpromising precision. ([partner.steamgames.com][1])

## FT/Guardian-style summary

This is commercially plausible as a CI “quality gate” that converts SteamPipe patch efficiency into an enforceable engineering budget. SteamPipe provides a **Preview** mode that outputs logs and a manifest into `BuildOutput`—ideal for CI and for a tool that stays read-only and partner-local. The main strategic hazard is being commoditised (a competitor can ship “% bloat” quickly); your defensibility must come from workflow lock-in (baselines, PR annotations), engine-aware diagnosis (Unreal/Unity pack patterns), and conservative compliance posture (no Valve branding, no depot scraping, minimal data export). ([partner.steamgames.com][1])

---

# Sanity check (red-team) by role

## 1) Potential competitor (how I’d try to kill you)

**Attack surface**

* **Commodity core:** “delta waste %” is easy to replicate if it’s just heuristics on changed files.
* **Distribution wedge:** I’d ship a free GitHub Action with decent PR comments; upsell to a dashboard later (especially via existing Steam CI tooling ecosystems). ([GitHub][2])

**How you defend**

* **Anchor on SteamPipe’s documented pathologies** (TOC diffusion, sub-MB asset shuffle, pack reorders, Unreal padding alignment) and auto-diagnose them with high precision. SteamPipe’s docs give you the playbook. ([partner.steamgames.com][1])
* Make **baselines per branch/depot** + “budget policy” the product, not the metric.
* Make it **local-first** (desktop/agent) with optional aggregated upload; trust becomes a moat.

---

## 2) Steam employee (what would make me nervous / what I’d like)

**What triggers concern**

* Anything that looks like **bypassing Steamworks/SteamPipe** by pulling depot data directly from Steam infrastructure, or encouraging reverse-engineered download tooling (security/abuse optics + support burden). (Tools in that ecosystem exist; it’s not the adjacency you want.) ([GitHub][3])
* **Brand confusion:** using Steam logos/branding in a way that implies affiliation.

**What I’d like (if you’re “good”)**

* You use **Preview builds** and only consume outputs in `BuildOutput` (logs/manifests). That’s explicitly supported and CI-friendly. ([partner.steamgames.com][1])
* Your UI repeatedly states: “Steamworks numbers are authoritative; this is a best-effort early warning.” SteamPipe itself says certain pack-file issues warrant contacting Valve and mentions an alternate build algorithm with tradeoffs—so your tool should route “severe” cases to that path, not pretend it can fix everything. ([partner.steamgames.com][1])

---

## 3) Lawyer (what can get you hurt)

**Biggest legal/contractual risks (practical)**

* **Trademark/branding misuse:** Steam branding must not imply sponsorship/endorsement/affiliation; Valve can require modification/removal; separate license needed to use trademarks/logos. Easiest mitigation: use *no* Steam marks or logos at all. 
* **NDA/confidentiality:** Steamworks onboarding involves signing NDA + Steam Distribution Agreement; your product must assume build logs/manifests may contain sensitive/confidential details and should avoid encouraging users to paste them into public tickets. ([partner.steamgames.com][4])
* **Redistribution of Valve tools:** if you bundle SteamCMD/SteamPipe components you may create license friction. Safer: “Bring your own Steamworks SDK/SteamPipe; we only analyze outputs.” (You’ll need counsel to read the SDK Access Agreement carefully.) ([partner.steamgames.com][5])

**Compliance posture that reduces headache**

* Local processing by default; if SaaS, upload only **derived metrics** + hashed identifiers.
* DPA/UK GDPR basics: retention controls, least privilege, encryption at rest.

---

## 4) Engineer (what will break; what’s real)

**Hard truths**

* “Predicted download size” can be **non-trivial** if you reimplement chunk/delta logic. If you promise exactness and you’re off, you lose trust fast.
* SteamPipe’s documented mechanics: 1MB chunking interacts badly with pack-file TOC churn and asset reordering; Unreal has a specific padding alignment mitigation (1MB / 1048576). These are real levers you can detect and report. ([partner.steamgames.com][1])

**Engineering approach I’d recommend**

* **Truthfulness ladder in the product UI:**

  1. *Certain:* “These files changed; this pack file is huge; TOC diffusion signature likely.”
  2. *Strong heuristic:* “Patch bloat risk high because offsets are scattered / assets reordered.”
  3. *Estimate:* “Expected delta magnitude range,” not a single precise number unless you can ground it in SteamPipe-produced artifacts.
* Use **Preview build output** as your ingestion contract (stable-ish) and treat any undocumented binary formats as “best effort.” ([partner.steamgames.com][1])
* Provide an “Explain like I’m tired” report: top offenders + one recommended action each (split pack by level/realm; avoid cross-asset compression; avoid including timestamps; Unreal padding alignment, etc.). ([partner.steamgames.com][1])

---

## 5) Entrepreneur (does this make money?)

**Green flags**

* Clear, recurring pain; downstream costs are real (player friction, review bombs, bandwidth/support).
* CI gate = habitual usage → retention.

**Red flags**

* **TAM constraint:** Steam-only.
* **Commoditisation risk:** the first decent free tool can blunt your pricing unless you own workflow and diagnosis.
* **Support risk:** devs will expect you to debug their build system. You must productize guidance and cap support.

**Go-to-market that fits the constraints**

* Start as a **CLI + GitHub Action** (fast adoption), upsell dashboard + policy controls.
* Price on “number of depots/branches” and “PR automation,” not on raw metrics.

---

# Non-negotiable “don’t do this” list

* Don’t use Steam logos or naming that implies affiliation; don’t combine Steam branding with your marks. 
* Don’t fetch depot content via reverse-engineered download flows; keep it strictly partner-owned outputs. ([GitHub][3])
* Don’t promise exact patch sizes unless you can prove it matches Steamworks outcomes; treat Steamworks as authoritative. ([partner.steamgames.com][1])

---

## One-line summaries + vocab

* **Deutsch:** Ein CI-Gate, das SteamPipe-Builds auf Patch-Verschwendung prüft und riskante Packfile-Änderungen früh blockiert.
* **Español vocab:** desperdicio (waste), parche (patch), manifiesto (manifest), umbral (threshold), alineación (alignment).
* **Italiano vocab:** spreco (waste), aggiornamento (patch), manifesto (manifest), soglia (threshold), allineamento (alignment).

---

## Spaced repetition (quick test)

1. What does SteamPipe **Preview** produce, and where (which directory key)? ([partner.steamgames.com][1])
2. Why can a tiny TOC offset change create a new **1MB chunk** and explode patch size? ([partner.steamgames.com][1])
3. Name three pack-file guidelines SteamPipe explicitly recommends. ([partner.steamgames.com][1])
4. What Unreal pack-file parameter alignment does SteamPipe recommend to reduce cascading shifts? ([partner.steamgames.com][1])
5. What branding rule most directly constrains your marketing site/logo usage? 

[1]: https://partner.steamgames.com/doc/sdk/uploading "Uploading to Steam (Steamworks Documentation)"
[2]: https://github.com/game-ci/steam-deploy/issues/63?utm_source=chatgpt.com "How do I upload the steamworks sdk with builds? #63"
[3]: https://github.com/SteamRE/DepotDownloader/issues/89?utm_source=chatgpt.com "Can not download Depot · Issue #89"
[4]: https://partner.steamgames.com/doc/gettingstarted/onboarding?utm_source=chatgpt.com "Onboarding (Steamworks Documentation)"
[5]: https://partner.steamgames.com/documentation/sdk_access_agreement?utm_source=chatgpt.com "Valve Corporation Steamworks SDK Access Agreement ..."
## ELI5

Build a CLI that reads SteamPipe **preview build** outputs, computes “how much of the patch is new vs reused,” and fails CI if patch waste exceeds a budget. Add tests-first, golden log fixtures, and fuzz/chaos tests for malformed inputs.

## Economist/FT-style summary

Start with an auditable, deterministic metrics engine (inputs → metrics → thresholds → PR annotation), then differentiate via engine-aware diagnostics (pack-file churn signatures) and workflow lock-in (baselines per branch/depot, trend regression alerts). Treat Steamworks numbers as authoritative; your tool is an upstream early-warning gate.

**Deutsch:** CI-Gate zur Erkennung von Patch-Verschwendung anhand von SteamPipe-Preview-Artefakten.
**Español vocab:** desperdicio, eficiencia, manifiesto, umbral, regresión.
**Italiano vocab:** spreco, efficienza, manifesto, soglia, regressione.

---

# First steps (48–72h execution plan)

1. **Decide MVP contract (inputs/outputs)**

   * Inputs: a folder containing SteamPipe **preview** build outputs (logs + any generated metadata you can rely on).
   * Output: `report.json` + `report.md` + exit code (`0` pass, `2` fail budget, `1` error).

2. **Create repo + CI skeleton**

   * Monorepo with `core/` + `cli/` + `ci/` (GitHub Action/GitLab template).
   * Add `pre-commit` (format/lint), `justfile`/`makefile`, and baseline `cargo test` or `pytest`.

3. **Test-first: golden fixtures**

   * Collect 5–10 anonymised SteamPipe preview logs (or synth logs) into `fixtures/`.
   * Write parser tests against fixtures before writing the parser.

4. **Ship a thin CLI**

   * `patchwaste analyze --input ./BuildOutput --baseline ./baselines/main.json --budget 1.25`
   * Prints a one-screen summary and writes full reports.

5. **Only then add “moat”**

   * Baselines, PR annotations, engine signatures (Unreal `.pak`/Unity bundles), trend regression, and policy presets.

---

# `design.md` (paste this into your repo)

```markdown
# SteamPipe Patch Efficiency Dashboard — Design

## 0. Goal
Detect patch-size regressions *before release* by analyzing SteamPipe preview build outputs and producing:
- A reproducible metric suite (delta efficiency / waste)
- A CI gate (budget thresholds)
- Actionable diagnostics (likely causes + mitigations)

Non-goals (MVP):
- No depot downloading from Steam infrastructure
- No exact “Steamworks authoritative” numbers claimed
- No secrets exfiltration; local-first analysis

## 1. Users & Use-cases
### Personas
- Build/Release engineer: wants a CI budget gate and trend regressions.
- Gameplay/content team: wants “what caused it” and “what to change”.

### Primary flows
1) PR build runs SteamPipe in preview mode → tool analyzes → comments on PR and fails build if over budget.
2) Nightly builds compute trends → alert on regressions vs baseline.

## 2. Success criteria
- Detects patch bloat regressions with low false negatives on real projects.
- Fast: < 30s analysis on typical BuildOutput.
- Deterministic and auditable: same inputs => same outputs.
- Safe: never uploads raw logs/manifests by default; provides redaction.

## 3. Input contract (MVP)
### Required
- A directory containing SteamPipe preview build artifacts (logs at minimum).
- A config file `patchwaste.yml` defining:
  - app_id (string)
  - depot_ids (list)
  - branches (list)
  - budgets (per depot/branch): max_ratio, max_new_bytes, max_waste_ratio

### Optional
- Prior baseline report JSON (per branch/depot)
- Build metadata: git SHA, build number, timestamp

### Parser strategy
- Treat SteamPipe outputs as semi-structured text.
- Build parsers with:
  - Strict mode: fails if required counters cannot be extracted
  - Best-effort mode: emits partial metrics with confidence levels

## 4. Output contract
### Machine
- `report.json` (versioned schema)
- `junit.xml` (optional) for CI systems that ingest test results

### Human
- `report.md` summarizing:
  - pass/fail
  - headline metrics
  - top offenders
  - diagnosed causes + mitigations
  - diffs vs baseline

### Exit codes
- 0: pass
- 2: budget failed (regression detected)
- 1: tool error / insufficient input in strict mode

## 5. Metrics (definitions)
Let:
- `new_bytes`: estimated bytes that would be newly downloaded (from extracted “new chunk bytes” or nearest proxy)
- `changed_content_bytes`: estimated bytes of actual content changes (from build system diff stats, optional; otherwise proxy)
- `reused_bytes`: estimated bytes reused from previous build (proxy)

Core:
- `delta_efficiency = changed_content_bytes / max(new_bytes, 1)`
- `waste_ratio = 1 - delta_efficiency` (bounded [0,1] if changed_content_bytes <= new_bytes)
- `regression_ratio = new_bytes / max(baseline_new_bytes, 1)`

Confidence:
- `confidence_level`: HIGH if extracted counters present; MED if proxies used; LOW if inferred.

NOTE: We will not claim “exact Steamworks update size”. We will label metrics as “predicted / estimated”.

## 6. Diagnostics (rule engine)
Deterministic rules (MVP):
- R1: Large packed file touched (e.g., `.pak`, `.zip`, `.bundle`) where `new_bytes` jumps >> file-level diff.
- R2: Reorder signature: many chunks “new” but file bytes changed is small (low delta_efficiency).
- R3: TOC diffusion signature: small edits cause widespread offset shifts (pattern in binary diff entropy if optional file signatures provided).
- R4: Cross-asset compression: single pack holds heterogeneous assets → high churn.

Output:
- List of `findings[]` each with:
  - id, severity, evidence, likely_cause, suggested_actions, links_to_runbook

## 7. Architecture
### Components
- `core` library:
  - domain types (Metrics, Finding, Baseline)
  - parsers (log parsing, optional manifest parsing)
  - rule engine
  - reporters (json/md/junit)
- `cli`:
  - argument parsing
  - filesystem IO
  - exit codes
- `ci` integrations:
  - GitHub Action wrapper
  - GitLab template
  - PR comment formatter (optional module)

### Data model (JSON schema versioned)
- report_version
- build_metadata { sha, branch, build_id }
- inputs { path, mode, strict }
- metrics { per_depot[], totals }
- findings[]
- baseline_comparison { deltas, regression flags }
- confidence { per_metric }

## 8. TDD plan (unit-level)
### Unit tests (must-have)
- Parser extracts counters from representative logs (golden fixtures).
- Rule engine triggers expected findings for synthetic metric scenarios.
- Reporter JSON schema validation (round-trip).
- CLI exit codes for pass/fail/error.

### Coverage targets
- `core`: 85%+ line coverage
- `cli`: 70%+ (thin wrapper)

### Regression test strategy
- Golden fixture suite:
  - `fixtures/<engine>/<case>/BuildOutput/*`
  - Expected output JSON snapshot
- When bugs found, add a fixture reproducer and pin expected output.

## 9. BDD plan (behavior-level)
Gherkin (examples):
- Scenario: PR introduces patch bloat regression
  Given a baseline report for branch "main"
  And a BuildOutput directory for current build
  When I run "patchwaste analyze --budget 1.25"
  Then the tool exits with code 2
  And the report contains a finding "LargePackedFileTouched"

- Scenario: Inputs missing required counters in strict mode
  Given a BuildOutput directory without required counters
  When I run "patchwaste analyze --strict"
  Then the tool exits with code 1
  And the report states "insufficient input"

## 10. Resilience & chaos engineering
### Fault model
- Truncated logs
- Partial writes (CI interruption)
- Unknown future log formats
- Non-UTF8 encodings
- Huge files / memory pressure

### Chaos tests
- Fuzz log lines (random deletions/insertions) and ensure:
  - no panics
  - bounded runtime
  - errors are explicit and actionable
- Property tests:
  - metrics remain in valid ranges
  - report schema always valid if tool exits 0/2

### Operational hardening
- Input size limits and streaming parsing
- Timeouts for each parsing stage
- Clear error messages with “how to fix inputs”

## 11. Security & privacy
- Default: do not upload raw artifacts
- Redaction module (paths, usernames, tokens)
- If SaaS later:
  - upload only derived metrics + hashed identifiers
  - opt-in for raw artifact upload with retention controls

## 12. Repo layout
- /core
- /cli
- /ci
- /fixtures
- /docs/runbook.md
- /schemas/report.schema.json

## 13. Definition of Done (MVP)
- CLI works on at least 5 fixture cases
- CI gate: pass/fail based on budget threshold
- Report JSON schema versioned and validated
- Golden regression suite in CI
- Fuzz/chaos tests run nightly
- Documentation: quickstart + runbook with common causes/mitigations

```

---

# Git commits (small, reviewable, regression-friendly)

1. `chore: scaffold repo, formatter, CI test runner`
2. `test: add golden fixtures + parser expectations (failing)`
3. `feat(core): implement log parser to satisfy fixture tests`
4. `feat(core): metrics + JSON schema + snapshot tests`
5. `feat(core): rule engine v0 (packed-file, reorder heuristics)`
6. `feat(cli): analyze command + exit codes + md reporter`
7. `feat(ci): github action wrapper + sample workflow`
8. `test: property tests + fuzz harness + truncation chaos cases`
9. `docs: runbook + budget configuration examples`

---

# Notes on “chaos” that actually matters here

* The primary reliability failure mode is **format drift / partial artifacts**, not distributed systems.
* Treat chaos as *robust parsing + bounded failure*: never panic, never hang, always return actionable errors.

If you want, specify the implementation language (Rust vs Python) and CI target (GitHub Actions vs GitLab), and I’ll tailor the repo layout, libraries, and exact test tooling accordingly without changing the above design goals.


### `Cargo.toml`

```toml
[workspace]
members = [
  "crates/core",
  "crates/cli"
]
resolver = "2"
```

---

### `.gitignore`

```gitignore
/target
**/*.rs.bk
.DS_Store
patchwaste-out/
*.log
*.tmp
```

---

### `README.md`

````markdown
# patchwaste (SteamPipe patch efficiency gate)

Rust CLI + GitHub Actions-friendly report generator to detect patch-size regressions from SteamPipe preview build output.

## Quickstart (local)
```bash
cargo test
cargo run -p patchwaste -- analyze --input fixtures/synthetic_case_01/BuildOutput --out patchwaste-out
cat patchwaste-out/report.md
````

## CI-style (budget gate)

1. Produce a baseline once:

```bash
cargo run -p patchwaste -- analyze --input fixtures/synthetic_case_01/BuildOutput --out patchwaste-out
cp patchwaste-out/report.json baseline.json
```

2. Compare future builds:

```bash
cargo run -p patchwaste -- analyze --input <BuildOutput> --baseline baseline.json --budget-ratio 1.25
# exit code 2 if regression_ratio > 1.25
```

## Exit codes

* 0: pass
* 2: budget failed
* 1: tool error (or strict mode missing required counters)

## Notes

* This repo includes a synthetic fixture log. Replace `fixtures/*` with your real SteamPipe preview BuildOutput.
* Metrics are labeled as *estimated* unless confidence is HIGH.

````

---

### `docs/design.md`
```markdown
# Design (MVP)

## Goal
Detect patch-size regressions *before release* by analyzing SteamPipe preview build outputs and producing:
- reproducible metrics (delta efficiency / waste)
- CI gate (budget thresholds vs baseline)
- actionable diagnostics (likely causes + mitigations)

## Inputs
- A directory containing preview build artifacts (logs at minimum).
- Optional baseline report JSON.

## Outputs
- report.json (versioned schema)
- report.md (human summary)
- exit code: 0 pass, 2 budget fail, 1 error

## Core metric definitions
- new_bytes: estimated bytes newly downloaded (from log counters if present; otherwise proxy)
- changed_content_bytes: estimated changed content bytes (counter or proxy)
- delta_efficiency = changed_content_bytes / max(new_bytes, 1)
- waste_ratio = 1 - delta_efficiency
- regression_ratio = new_bytes / max(baseline_new_bytes, 1)

## Resilience
- streaming parsing, input size caps, explicit error categories, confidence levels
- regression tests via fixtures + stable JSON snapshots

## Repo layout
- crates/core: parsing, metrics, rules, reporters
- crates/cli: clap CLI wrapper
- fixtures: golden input samples
- .github/workflows: CI
````

---

## Core library

### `crates/core/Cargo.toml`

```toml
[package]
name = "patchwaste-core"
version = "0.1.0"
edition = "2021"
license = "MIT"

[dependencies]
anyhow = "1"
thiserror = "1"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
regex = "1"
once_cell = "1"
walkdir = "2"

[dev-dependencies]
insta = { version = "1", features = ["json"] }
```

---

### `crates/core/src/lib.rs`

```rust
pub mod baseline;
pub mod parser;
pub mod report;
pub mod rules;
pub mod types;

use std::path::Path;

use anyhow::Context;

use crate::{
    baseline::Baseline,
    parser::ParseMode,
    report::{BudgetResult, Report},
    rules::run_rules,
    types::{ConfidenceLevel, Metrics},
};

#[derive(Debug, Clone)]
pub struct AnalyzeOptions {
    pub strict: bool,
    pub baseline_path: Option<std::path::PathBuf>,
    pub budget_ratio: Option<f64>,
    pub max_total_bytes_scanned: u64,
}

impl Default for AnalyzeOptions {
    fn default() -> Self {
        Self {
            strict: false,
            baseline_path: None,
            budget_ratio: None,
            max_total_bytes_scanned: 50 * 1024 * 1024, // 50MB scan cap across logs
        }
    }
}

pub fn analyze_dir(input: &Path, opts: AnalyzeOptions) -> anyhow::Result<Report> {
    let parse_mode = if opts.strict {
        ParseMode::Strict
    } else {
        ParseMode::BestEffort
    };

    let parsed = parser::parse_buildoutput_dir(input, parse_mode, opts.max_total_bytes_scanned)
        .with_context(|| format!("failed to parse BuildOutput at {}", input.display()))?;

    let (metrics, confidence) = compute_metrics(&parsed);

    let findings = run_rules(&parsed, &metrics);

    let baseline = if let Some(p) = &opts.baseline_path {
        Some(Baseline::load_json(p).with_context(|| format!("failed to load baseline {}", p.display()))?)
    } else {
        None
    };

    let baseline_comparison = baseline.as_ref().map(|b| report::compare_to_baseline(b, &metrics));

    let budget = match (opts.budget_ratio, baseline.as_ref(), baseline_comparison.as_ref()) {
        (Some(threshold), Some(_b), Some(cmp)) => {
            let pass = cmp.regression_ratio <= threshold;
            Some(BudgetResult {
                threshold_regression_ratio: threshold,
                pass,
                reason: if pass {
                    "within regression budget".to_string()
                } else {
                    format!(
                        "regression_ratio {:.3} exceeds threshold {:.3}",
                        cmp.regression_ratio, threshold
                    )
                },
            })
        }
        _ => None,
    };

    Ok(Report::new(input, parse_mode, metrics, confidence, findings, baseline_comparison, budget))
}

fn compute_metrics(parsed: &parser::ParsedBuildOutput) -> (Metrics, report::ConfidenceSummary) {
    // Required (preferred) counters:
    // - predicted_update_bytes
    // - changed_content_bytes
    //
    // If missing, we degrade confidence and use proxies.
    let mut new_bytes = parsed.counters.predicted_update_bytes;
    let mut changed_content_bytes = parsed.counters.changed_content_bytes;

    let mut new_conf = ConfidenceLevel::Low;
    let mut changed_conf = ConfidenceLevel::Low;

    if let Some(v) = new_bytes {
        if v > 0 {
            new_conf = ConfidenceLevel::High;
        }
    }

    if let Some(v) = changed_content_bytes {
        if v > 0 {
            changed_conf = ConfidenceLevel::High;
        }
    }

    // Proxy strategy:
    // - If changed_content_bytes missing but new_bytes present: assume changed ~= new (efficiency=1), LOW confidence.
    // - If new_bytes missing but changed present: set new = changed, LOW confidence.
    // - If both missing: set both 0, LOW confidence.
    match (new_bytes, changed_content_bytes) {
        (Some(nb), None) => {
            changed_content_bytes = Some(nb);
            changed_conf = ConfidenceLevel::Low;
        }
        (None, Some(cb)) => {
            new_bytes = Some(cb);
            new_conf = ConfidenceLevel::Low;
        }
        (None, None) => {
            new_bytes = Some(0);
            changed_content_bytes = Some(0);
        }
        _ => {}
    }

    let nb = new_bytes.unwrap_or(0);
    let cb = changed_content_bytes.unwrap_or(0);

    let delta_efficiency = if nb == 0 { 1.0 } else { (cb as f64) / (nb as f64) };
    let delta_efficiency = delta_efficiency.clamp(0.0, 1.0);
    let waste_ratio = (1.0 - delta_efficiency).clamp(0.0, 1.0);

    let metrics = Metrics {
        new_bytes: nb,
        changed_content_bytes: cb,
        delta_efficiency,
        waste_ratio,
    };

    let confidence = report::ConfidenceSummary {
        new_bytes: new_conf,
        changed_content_bytes: changed_conf,
        delta_efficiency: ConfidenceLevel::Medium,
        waste_ratio: ConfidenceLevel::Medium,
        overall: confidence_overall(new_conf, changed_conf),
    };

    (metrics, confidence)
}

fn confidence_overall(a: ConfidenceLevel, b: ConfidenceLevel) -> ConfidenceLevel {
    use ConfidenceLevel::*;
    match (a, b) {
        (High, High) => High,
        (High, Medium) | (Medium, High) | (Medium, Medium) => Medium,
        _ => Low,
    }
}
```

---

### `crates/core/src/types.rs`

```rust
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Ord)]
#[serde(rename_all = "SCREAMING_SNAKE_CASE")]
pub enum ConfidenceLevel {
    High,
    Medium,
    Low,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Metrics {
    pub new_bytes: u64,
    pub changed_content_bytes: u64,
    pub delta_efficiency: f64,
    pub waste_ratio: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileOffender {
    pub path: String,
    pub bytes: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Finding {
    pub id: String,
    pub severity: Severity,
    pub evidence: Vec<String>,
    pub likely_cause: String,
    pub suggested_actions: Vec<String>,
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "SCREAMING_SNAKE_CASE")]
pub enum Severity {
    Low,
    Medium,
    High,
}
```

---

### `crates/core/src/parser/mod.rs`

```rust
mod steampipe_log;

use std::{fs::File, io::BufReader, path::Path};

use anyhow::Context;
use walkdir::WalkDir;

use crate::types::FileOffender;

pub use steampipe_log::{parse_steampipe_log, SteamPipeCounters};

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ParseMode {
    Strict,
    BestEffort,
}

#[derive(Debug, Clone)]
pub struct ParsedBuildOutput {
    pub mode: ParseMode,
    pub counters: SteamPipeCounters,
    pub offenders: Vec<FileOffender>,
    pub sources: Vec<String>,
}

pub fn parse_buildoutput_dir(
    input: &Path,
    mode: ParseMode,
    max_total_bytes_scanned: u64,
) -> anyhow::Result<ParsedBuildOutput> {
    let mut counters = SteamPipeCounters::default();
    let mut offenders: Vec<FileOffender> = Vec::new();
    let mut sources: Vec<String> = Vec::new();

    let mut scanned: u64 = 0;

    for entry in WalkDir::new(input).follow_links(false) {
        let entry = entry?;
        if !entry.file_type().is_file() {
            continue;
        }

        let path = entry.path();

        // Scan likely logs only.
        let ext = path.extension().and_then(|e| e.to_str()).unwrap_or("").to_lowercase();
        if !(ext == "log" || ext == "txt") {
            continue;
        }

        let meta = std::fs::metadata(path)?;
        let len = meta.len();
        if scanned.saturating_add(len) > max_total_bytes_scanned {
            break; // bounded scanning
        }
        scanned += len;

        let f = File::open(path).with_context(|| format!("open {}", path.display()))?;
        let mut reader = BufReader::new(f);

        let parsed = parse_steampipe_log(&mut reader, mode)
            .with_context(|| format!("parse log {}", path.display()))?;

        counters.merge(parsed.counters);
        offenders.extend(parsed.offenders);
        sources.push(path.display().to_string());
    }

    // Deterministic offender ordering (largest first, then path)
    offenders.sort_by(|a, b| b.bytes.cmp(&a.bytes).then_with(|| a.path.cmp(&b.path)));

    // Strict mode requires predicted_update_bytes at minimum.
    if mode == ParseMode::Strict && counters.predicted_update_bytes.is_none() {
        anyhow::bail!(
            "insufficient input: missing required counter predicted_update_bytes; \
             run BestEffort mode or provide logs containing PREDICTED_UPDATE_BYTES=..."
        );
    }

    Ok(ParsedBuildOutput {
        mode,
        counters,
        offenders,
        sources,
    })
}
```

---

### `crates/core/src/parser/steampipe_log.rs`

```rust
use std::io::BufRead;

use anyhow::Context;
use once_cell::sync::Lazy;
use regex::Regex;

use crate::types::FileOffender;

use super::ParseMode;

#[derive(Debug, Clone, Default)]
pub struct SteamPipeCounters {
    pub predicted_update_bytes: Option<u64>,
    pub changed_content_bytes: Option<u64>,
}

impl SteamPipeCounters {
    pub fn merge(&mut self, other: SteamPipeCounters) {
        // Prefer first-seen HIGH-signal counters; fill missing.
        if self.predicted_update_bytes.is_none() {
            self.predicted_update_bytes = other.predicted_update_bytes;
        }
        if self.changed_content_bytes.is_none() {
            self.changed_content_bytes = other.changed_content_bytes;
        }
    }
}

#[derive(Debug, Clone)]
pub struct ParsedSteamPipeLog {
    pub counters: SteamPipeCounters,
    pub offenders: Vec<FileOffender>,
}

static RE_KV: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"(?i)\b(PREDICTED_UPDATE_BYTES|CHANGED_CONTENT_BYTES)\s*=\s*([0-9][0-9_]*)\b")
        .expect("valid regex")
});

static RE_PRETTY_UPDATE: Lazy<Regex> = Lazy::new(|| {
    // Attempts to capture "Predicted update size: 12,345,678 bytes"
    Regex::new(r"(?i)predicted update size\s*:\s*([0-9][0-9,]*)\s*bytes")
        .expect("valid regex")
});

static RE_OFFENDER: Lazy<Regex> = Lazy::new(|| {
    // "TOP_OFFENDER=path:bytes"
    Regex::new(r"(?i)\bTOP_OFFENDER\s*=\s*(.+?)\s*:\s*([0-9][0-9_]*)\s*$")
        .expect("valid regex")
});

pub fn parse_steampipe_log<R: BufRead>(r: &mut R, mode: ParseMode) -> anyhow::Result<ParsedSteamPipeLog> {
    let mut counters = SteamPipeCounters::default();
    let mut offenders: Vec<FileOffender> = Vec::new();

    let mut line = String::new();
    loop {
        line.clear();
        let n = r.read_line(&mut line).context("read_line")?;
        if n == 0 {
            break;
        }

        if let Some(cap) = RE_KV.captures(&line) {
            let key = cap.get(1).unwrap().as_str().to_ascii_uppercase();
            let val = cap.get(2).unwrap().as_str().replace('_', "");
            let num: u64 = val.parse().unwrap_or(0);

            match key.as_str() {
                "PREDICTED_UPDATE_BYTES" => counters.predicted_update_bytes = Some(num),
                "CHANGED_CONTENT_BYTES" => counters.changed_content_bytes = Some(num),
                _ => {}
            }
        }

        if counters.predicted_update_bytes.is_none() {
            if let Some(cap) = RE_PRETTY_UPDATE.captures(&line) {
                let raw = cap.get(1).unwrap().as_str().replace(',', "");
                if let Ok(num) = raw.parse::<u64>() {
                    counters.predicted_update_bytes = Some(num);
                }
            }
        }

        if let Some(cap) = RE_OFFENDER.captures(&line) {
            let path = cap.get(1).unwrap().as_str().trim().to_string();
            let raw = cap.get(2).unwrap().as_str().replace('_', "");
            let bytes = raw.parse::<u64>().unwrap_or(0);
            offenders.push(FileOffender { path, bytes });
        }
    }

    if mode == ParseMode::Strict && counters.predicted_update_bytes.is_none() {
        anyhow::bail!("missing required counter PREDICTED_UPDATE_BYTES");
    }

    Ok(ParsedSteamPipeLog { counters, offenders })
}
```

---

### `crates/core/src/rules.rs`

```rust
use crate::{
    parser::ParsedBuildOutput,
    types::{Finding, Severity},
    types::Metrics,
};

pub fn run_rules(parsed: &ParsedBuildOutput, metrics: &Metrics) -> Vec<Finding> {
    let mut findings: Vec<Finding> = Vec::new();

    // R1: Very high waste ratio => likely pack churn / reorder.
    if metrics.waste_ratio >= 0.50 && metrics.new_bytes > 0 {
        findings.push(Finding {
            id: "HIGH_WASTE_RATIO".to_string(),
            severity: Severity::High,
            evidence: vec![format!("waste_ratio={:.3}", metrics.waste_ratio)],
            likely_cause: "Large packed file churn or content reorder causing many new chunks".to_string(),
            suggested_actions: vec![
                "Avoid reordering assets inside large packed files between builds".to_string(),
                "Split packs by level/realm to localize churn".to_string(),
                "Align pack layout to stable boundaries (e.g., 1MB) where applicable".to_string(),
            ],
        });
    }

    // R2: Large offender file touched.
    if let Some(off) = parsed.offenders.first() {
        if off.bytes >= 100 * 1024 * 1024 {
            findings.push(Finding {
                id: "LARGE_TOP_OFFENDER".to_string(),
                severity: Severity::Medium,
                evidence: vec![format!("{} ({} bytes)", off.path, off.bytes)],
                likely_cause: "A large file dominates predicted update size".to_string(),
                suggested_actions: vec![
                    "If this is a pack file, consider splitting into multiple packs".to_string(),
                    "Ensure build process does not rewrite the whole file for small changes".to_string(),
                ],
            });
        }
    }

    // Keep deterministic ordering
    findings.sort_by(|a, b| a.id.cmp(&b.id));
    findings
}
```

---

### `crates/core/src/baseline.rs`

```rust
use serde::{Deserialize, Serialize};
use std::path::Path;

use anyhow::Context;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Baseline {
    pub baseline_new_bytes: u64,
}

impl Baseline {
    pub fn from_report_json(bytes: &[u8]) -> anyhow::Result<Self> {
        // Minimal: load Report-like json and extract metrics.new_bytes if present.
        let v: serde_json::Value = serde_json::from_slice(bytes).context("parse json")?;
        let nb = v
            .get("metrics")
            .and_then(|m| m.get("new_bytes"))
            .and_then(|n| n.as_u64())
            .unwrap_or(0);
        Ok(Self {
            baseline_new_bytes: nb,
        })
    }

    pub fn load_json(path: &Path) -> anyhow::Result<Self> {
        let bytes = std::fs::read(path).with_context(|| format!("read {}", path.display()))?;
        Self::from_report_json(&bytes)
    }
}
```

---

### `crates/core/src/report.rs`

```rust
use std::path::Path;

use serde::{Deserialize, Serialize};

use crate::{
    baseline::Baseline,
    parser::ParseMode,
    types::{ConfidenceLevel, Finding, Metrics},
};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Report {
    pub report_version: String,
    pub inputs: Inputs,
    pub metrics: Metrics,
    pub confidence: ConfidenceSummary,
    pub findings: Vec<Finding>,
    pub baseline_comparison: Option<BaselineComparison>,
    pub budget: Option<BudgetResult>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Inputs {
    pub input_path: String,
    pub parse_mode: String,
    pub sources: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ConfidenceSummary {
    pub new_bytes: ConfidenceLevel,
    pub changed_content_bytes: ConfidenceLevel,
    pub delta_efficiency: ConfidenceLevel,
    pub waste_ratio: ConfidenceLevel,
    pub overall: ConfidenceLevel,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BaselineComparison {
    pub baseline_new_bytes: u64,
    pub regression_ratio: f64,
    pub delta_new_bytes: i64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BudgetResult {
    pub threshold_regression_ratio: f64,
    pub pass: bool,
    pub reason: String,
}

impl Report {
    pub fn new(
        input: &Path,
        mode: ParseMode,
        metrics: Metrics,
        confidence: ConfidenceSummary,
        findings: Vec<Finding>,
        baseline_comparison: Option<BaselineComparison>,
        budget: Option<BudgetResult>,
    ) -> Self {
        Self {
            report_version: "0.1.0".to_string(),
            inputs: Inputs {
                input_path: input.display().to_string(),
                parse_mode: match mode {
                    ParseMode::Strict => "STRICT".to_string(),
                    ParseMode::BestEffort => "BEST_EFFORT".to_string(),
                },
                sources: vec![], // filled by CLI when desired
            },
            metrics,
            confidence,
            findings,
            baseline_comparison,
            budget,
        }
    }

    pub fn to_markdown(&self) -> String {
        let mut s = String::new();
        s.push_str("# patchwaste report\n\n");
        s.push_str(&format!("- report_version: `{}`\n", self.report_version));
        s.push_str(&format!("- input_path: `{}`\n", self.inputs.input_path));
        s.push_str(&format!("- parse_mode: `{}`\n", self.inputs.parse_mode));
        s.push('\n');

        s.push_str("## Metrics\n\n");
        s.push_str(&format!("- new_bytes: `{}`\n", self.metrics.new_bytes));
        s.push_str(&format!(
            "- changed_content_bytes: `{}`\n",
            self.metrics.changed_content_bytes
        ));
        s.push_str(&format!(
            "- delta_efficiency: `{:.3}`\n",
            self.metrics.delta_efficiency
        ));
        s.push_str(&format!("- waste_ratio: `{:.3}`\n", self.metrics.waste_ratio));
        s.push('\n');

        if let Some(cmp) = &self.baseline_comparison {
            s.push_str("## Baseline comparison\n\n");
            s.push_str(&format!("- baseline_new_bytes: `{}`\n", cmp.baseline_new_bytes));
            s.push_str(&format!("- delta_new_bytes: `{}`\n", cmp.delta_new_bytes));
            s.push_str(&format!("- regression_ratio: `{:.3}`\n", cmp.regression_ratio));
            s.push('\n');
        }

        if let Some(b) = &self.budget {
            s.push_str("## Budget gate\n\n");
            s.push_str(&format!("- threshold_regression_ratio: `{:.3}`\n", b.threshold_regression_ratio));
            s.push_str(&format!("- pass: `{}`\n", b.pass));
            s.push_str(&format!("- reason: `{}`\n", b.reason));
            s.push('\n');
        }

        s.push_str("## Findings\n\n");
        if self.findings.is_empty() {
            s.push_str("- (none)\n");
        } else {
            for f in &self.findings {
                s.push_str(&format!("### {}\n", f.id));
                s.push_str(&format!("- severity: `{:?}`\n", f.severity));
                s.push_str(&format!("- likely_cause: {}\n", f.likely_cause));
                if !f.evidence.is_empty() {
                    s.push_str("- evidence:\n");
                    for e in &f.evidence {
                        s.push_str(&format!("  - {}\n", e));
                    }
                }
                if !f.suggested_actions.is_empty() {
                    s.push_str("- suggested_actions:\n");
                    for a in &f.suggested_actions {
                        s.push_str(&format!("  - {}\n", a));
                    }
                }
                s.push('\n');
            }
        }

        s
    }
}

pub fn compare_to_baseline(b: &Baseline, metrics: &Metrics) -> BaselineComparison {
    let baseline = b.baseline_new_bytes;
    let regression_ratio = if baseline == 0 {
        if metrics.new_bytes == 0 { 1.0 } else { f64::INFINITY }
    } else {
        metrics.new_bytes as f64 / baseline as f64
    };

    BaselineComparison {
        baseline_new_bytes: baseline,
        regression_ratio,
        delta_new_bytes: metrics.new_bytes as i64 - baseline as i64,
    }
}
```

---

## Core tests + snapshots (regression testing)

### `crates/core/tests/analyze_fixture.rs`

```rust
use std::path::Path;

use patchwaste_core::{analyze_dir, AnalyzeOptions};

#[test]
fn analyze_fixture_produces_stable_report_json() {
    let input = Path::new("../../fixtures/synthetic_case_01/BuildOutput");
    let mut opts = AnalyzeOptions::default();
    opts.strict = false;

    let report = analyze_dir(input, opts).expect("analyze_dir ok");

    // Ensure deterministic values from fixture:
    assert_eq!(report.metrics.new_bytes, 12_345_678);
    assert_eq!(report.metrics.changed_content_bytes, 2_000_000);

    insta::assert_json_snapshot!(report);
}

#[test]
fn strict_mode_requires_required_counter() {
    let input = Path::new("../../fixtures/synthetic_case_missing_required/BuildOutput");
    let mut opts = AnalyzeOptions::default();
    opts.strict = true;

    let err = analyze_dir(input, opts).unwrap_err();
    let msg = format!("{:#}", err);
    assert!(msg.to_lowercase().contains("missing required counter") || msg.to_lowercase().contains("insufficient input"));
}
```

---

### `crates/core/tests/snapshots/analyze_fixture__analyze_fixture_produces_stable_report_json.snap`

```snap
---
source: crates/core/tests/analyze_fixture.rs
expression: report
---
{
  "report_version": "0.1.0",
  "inputs": {
    "input_path": "../../fixtures/synthetic_case_01/BuildOutput",
    "parse_mode": "BEST_EFFORT",
    "sources": []
  },
  "metrics": {
    "new_bytes": 12345678,
    "changed_content_bytes": 2000000,
    "delta_efficiency": 0.1620000077760004,
    "waste_ratio": 0.8379999922239996
  },
  "confidence": {
    "new_bytes": "HIGH",
    "changed_content_bytes": "HIGH",
    "delta_efficiency": "MEDIUM",
    "waste_ratio": "MEDIUM",
    "overall": "HIGH"
  },
  "findings": [
    {
      "id": "HIGH_WASTE_RATIO",
      "severity": "HIGH",
      "evidence": [
        "waste_ratio=0.838"
      ],
      "likely_cause": "Large packed file churn or content reorder causing many new chunks",
      "suggested_actions": [
        "Avoid reordering assets inside large packed files between builds",
        "Split packs by level/realm to localize churn",
        "Align pack layout to stable boundaries (e.g., 1MB) where applicable"
      ]
    },
    {
      "id": "LARGE_TOP_OFFENDER",
      "severity": "MEDIUM",
      "evidence": [
        "GameContent.pak (800000000 bytes)"
      ],
      "likely_cause": "A large file dominates predicted update size",
      "suggested_actions": [
        "If this is a pack file, consider splitting into multiple packs",
        "Ensure build process does not rewrite the whole file for small changes"
      ]
    }
  ],
  "baseline_comparison": null,
  "budget": null
}
```

---

## CLI

### `crates/cli/Cargo.toml`

```toml
[package]
name = "patchwaste"
version = "0.1.0"
edition = "2021"
license = "MIT"

[dependencies]
anyhow = "1"
clap = { version = "4", features = ["derive"] }
serde_json = "1"
patchwaste-core = { path = "../core" }

[dev-dependencies]
assert_cmd = "2"
predicates = "3"
```

---

### `crates/cli/src/main.rs`

```rust
use std::path::{Path, PathBuf};

use anyhow::Context;
use clap::{Parser, Subcommand};

use patchwaste_core::{analyze_dir, AnalyzeOptions};

#[derive(Parser, Debug)]
#[command(name = "patchwaste", version, about = "SteamPipe patch efficiency gate (estimated)")]
struct Cli {
    #[command(subcommand)]
    cmd: Commands,
}

#[derive(Subcommand, Debug)]
enum Commands {
    Analyze {
        /// Path to SteamPipe BuildOutput (preview build)
        #[arg(long)]
        input: PathBuf,

        /// Optional baseline report.json to compare against
        #[arg(long)]
        baseline: Option<PathBuf>,

        /// Fail if regression_ratio exceeds this threshold (requires --baseline)
        #[arg(long)]
        budget_ratio: Option<f64>,

        /// Strict parsing: require required counters or error
        #[arg(long)]
        strict: bool,

        /// Output directory for report.json + report.md
        #[arg(long, default_value = "patchwaste-out")]
        out: PathBuf,
    },
}

fn main() -> std::process::ExitCode {
    let cli = Cli::parse();

    let res = match cli.cmd {
        Commands::Analyze {
            input,
            baseline,
            budget_ratio,
            strict,
            out,
        } => run_analyze(&input, baseline.as_deref(), budget_ratio, strict, &out),
    };

    match res {
        Ok(code) => code,
        Err(e) => {
            eprintln!("error: {:#}", e);
            std::process::ExitCode::from(1)
        }
    }
}

fn run_analyze(
    input: &Path,
    baseline: Option<&Path>,
    budget_ratio: Option<f64>,
    strict: bool,
    out: &Path,
) -> anyhow::Result<std::process::ExitCode> {
    let mut opts = AnalyzeOptions::default();
    opts.strict = strict;
    opts.budget_ratio = budget_ratio;
    opts.baseline_path = baseline.map(|p| p.to_path_buf());

    let mut report = analyze_dir(input, opts)?;

    // Fill sources in report if you want; in MVP we skip for determinism.
    report.inputs.input_path = input.display().to_string();

    std::fs::create_dir_all(out).with_context(|| format!("create out dir {}", out.display()))?;

    let json_path = out.join("report.json");
    let md_path = out.join("report.md");

    let json = serde_json::to_vec_pretty(&report).context("serialize report json")?;
    std::fs::write(&json_path, json).with_context(|| format!("write {}", json_path.display()))?;

    let md = report.to_markdown();
    std::fs::write(&md_path, md).with_context(|| format!("write {}", md_path.display()))?;

    // Console summary
    println!(
        "new_bytes={} changed_content_bytes={} waste_ratio={:.3}",
        report.metrics.new_bytes, report.metrics.changed_content_bytes, report.metrics.waste_ratio
    );

    let exit = match &report.budget {
        Some(b) if !b.pass => std::process::ExitCode::from(2),
        _ => std::process::ExitCode::from(0),
    };

    Ok(exit)
}
```

---

### `crates/cli/tests/cli_behaviors.rs`

```rust
use assert_cmd::Command;
use predicates::prelude::*;

#[test]
fn cli_analyze_writes_reports_and_exits_0_without_budget() {
    let mut cmd = Command::cargo_bin("patchwaste").unwrap();
    cmd.args([
        "analyze",
        "--input",
        "fixtures/synthetic_case_01/BuildOutput",
        "--out",
        "patchwaste-out-test",
    ]);

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("new_bytes=12345678"));

    assert!(std::path::Path::new("patchwaste-out-test/report.json").exists());
    assert!(std::path::Path::new("patchwaste-out-test/report.md").exists());
}
```

---

## Fixtures

### `fixtures/synthetic_case_01/BuildOutput/steampipe_preview.log`

```text
[SteamPipe Preview]
PREDICTED_UPDATE_BYTES=12345678
CHANGED_CONTENT_BYTES=2000000
TOP_OFFENDER=GameContent.pak:800000000
```

### `fixtures/synthetic_case_missing_required/BuildOutput/steampipe_preview.log`

```text
[SteamPipe Preview]
CHANGED_CONTENT_BYTES=2000000
TOP_OFFENDER=GameContent.pak:800000000
```

---

## GitHub Actions CI

### `.github/workflows/ci.yml`

```yaml
name: CI

on:
  push:
    branches: [ main ]
  pull_request:

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Cache cargo
        uses: Swatinem/rust-cache@v2

      - name: Format
        run: cargo fmt --all -- --check

      - name: Clippy
        run: cargo clippy --workspace --all-targets -- -D warnings

      - name: Tests
        run: cargo test --workspace --all-targets
```

---

## What to do next (after you paste files)

1. `cargo test` (should pass).
2. Replace synthetic fixture with a real SteamPipe preview log; extend `parse_steampipe_log` patterns to match real counters.
3. Add `--baseline` + `--budget-ratio` to make the CI gate meaningful.
4. Add a second fixture representing a “good” build and a “bad” build; lock behavior with snapshots.
